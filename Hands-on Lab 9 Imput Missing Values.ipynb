{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Impute Missing Values**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will practice essential data wrangling techniques using the Stack Overflow survey dataset. The primary focus is on handling missing data and ensuring data quality. You will:\n",
    "\n",
    "- **Load the Data:** Import the dataset into a DataFrame using the pandas library.\n",
    "\n",
    "- **Clean the Data:** Identify and remove duplicate entries to maintain data integrity.\n",
    "\n",
    "- **Handle Missing Values:** Detect missing values, impute them with appropriate strategies, and verify the imputation to create a complete and reliable dataset for analysis.\n",
    "\n",
    "This lab equips you with the skills to effectively preprocess and clean real-world datasets, a crucial step in any data analysis project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Identify missing values in the dataset.\n",
    "\n",
    "-   Apply techniques to impute missing values in the dataset.\n",
    "  \n",
    "-   Use suitable techniques to normalize data in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install needed library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.23.2 (from pandas)\n",
      "  Downloading numpy-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.1 pandas-2.2.3 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset Into a Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Read Data**\n",
    "<p>\n",
    "The functions below will download the dataset into your browser:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...           0.00   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1           0.00           0.00           0.00            0.00   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1            0.00                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to ensure it loaded correctly\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Finding and Removing Duplicates\n",
    "##### Task 1: Identify duplicate rows in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2: Remove the duplicate rows from the dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Finding Missing Values\n",
    "##### Task 3: Find the missing values for all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Column  Missing Values  Total Rows\n",
      "0    AINextMuch less integrated           64289       65437\n",
      "1         AINextLess integrated           63082       65437\n",
      "2               AINextNo change           52939       65437\n",
      "3    AINextMuch more integrated           51999       65437\n",
      "4               EmbeddedAdmired           48704       65437\n",
      "..                          ...             ...         ...\n",
      "104                   YearsCode            5568       65437\n",
      "105                  NEWSOSites            5151       65437\n",
      "106                   LearnCode            4949       65437\n",
      "107                     EdLevel            4653       65437\n",
      "108                    AISelect            4530       65437\n",
      "\n",
      "[109 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "columns_with_missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "df_missing=columns_with_missing_values[columns_with_missing_values > 0]\n",
    "\n",
    "df_missing_summary = pd.DataFrame({\n",
    "    'Column': df_missing.index,\n",
    "    'Missing Values': df_missing.values,\n",
    "    'Total Rows': [df.shape[0]] * len(df_missing)\n",
    "})\n",
    "\n",
    "# Display the result\n",
    "print(df_missing_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column to check\n",
    "column_name = 'RemoteWork'\n",
    "\n",
    "# Step 1: Get the number of missing values for the specific column\n",
    "missing_count = df[column_name].isnull().sum()\n",
    "\n",
    "# Step 2: Display the column name and missing count\n",
    "column_summary = pd.DataFrame({\n",
    "    'Column': [column_name],\n",
    "    'Missing Values': [missing_count],\n",
    "    'Total Rows': [df.shape[0]]\n",
    "})\n",
    "\n",
    "# Show the result\n",
    "#print(column_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Total Rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>RemoteWork</td>\n",
       "      <td>10631</td>\n",
       "      <td>65437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Column  Missing Values  Total Rows\n",
       "90  RemoteWork           10631       65437"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_work_summary = df_missing_summary[df_missing_summary['Column'] == 'RemoteWork']\n",
    "remote_work_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_with_count={}\n",
    "df['RemoteWork'].isnull()\n",
    "most_frequent_with_count = {}\n",
    "\n",
    "# List of columns to process\n",
    "cols = ['RemoteWork', 'Employment']\n",
    "\n",
    "# Loop through each column to calculate mode and counts\n",
    "for col in cols:\n",
    "    # Get the mode of the column (ignores NaN by default)\n",
    "    modes = df[col].mode()\n",
    "    \n",
    "    # Get the value counts of the column, including NaN by setting dropna=False\n",
    "    counts = df[col].value_counts(dropna=False)\n",
    "    #print(f\"{col} ----{counts}\")\n",
    "    \n",
    "    # Check if there are any NaN values and add it to the mode if necessary\n",
    "    if df[col].isnull().any():\n",
    "        modes = pd.concat([modes, pd.Series([None])], ignore_index=True)  # Add NaN/None to the modes\n",
    "    \n",
    "    # Create a dictionary of mode values and their respective counts\n",
    "    most_frequent_values = {mode: counts.get(mode, 0) for mode in modes}\n",
    "    \n",
    "    # Store the result in the dictionary for the specific column\n",
    "    most_frequent_with_count[col] = most_frequent_values\n",
    "\n",
    "# Convert the dictionary to a DataFrame and transpose it for better readability\n",
    "most_frequent_df = pd.DataFrame(most_frequent_with_count).T\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "#print(most_frequent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4: Find out how many rows are missing in the column RemoteWork.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'RemoteWork' column: 10631\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "missing_rows = df['RemoteWork'].isnull().sum()\n",
    "print(f\"Number of missing values in 'RemoteWork' column: {missing_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Imputing Missing Values\n",
    "##### Task 5: Find the value counts for the column RemoteWork.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'RemoteWork' column: RemoteWork\n",
      "Hybrid (some remote, some in-person)    23015\n",
      "Remote                                  20831\n",
      "In-person                               10960\n",
      "NaN                                     10631\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "remote_work_value_counts = df['RemoteWork'].value_counts(dropna=False)\n",
    "print(f\"Number of missing values in 'RemoteWork' column: {remote_work_value_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 6: Identify the most frequent (majority) value in the RemoteWork column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid (some remote, some in-person) Hybrid (some remote, some in-person)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "most_frequent_remote_work = df['RemoteWork'].mode()[0]\n",
    "most_frequent_remote_work_vc = df['RemoteWork'].value_counts(dropna=False).idxmax()\n",
    "\n",
    "print(f\"{most_frequent_remote_work_vc} {most_frequent_remote_work}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 7: Impute (replace) all the empty rows in the column RemoteWork with the majority value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RemoteWork\n",
      "Hybrid (some remote, some in-person)    33646\n",
      "Remote                                  20831\n",
      "In-person                               10960\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82/3324728283.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['RemoteWork'].fillna(most_frequent_remote_work, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "df['RemoteWork'].fillna(most_frequent_remote_work, inplace=True)\n",
    "print(df['RemoteWork'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 8: Check for any compensation-related columns and describe their distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvertedCompYearly    42002\n",
      "CompTotal              31697\n",
      "dtype: int64\n",
      "After Capping and Imputation (Missing Values Filled with Mode):\n",
      "          CompTotal  ConvertedCompYearly\n",
      "65436 10,000,000.00            64,444.00\n",
      "0     10,000,000.00            64,444.00\n",
      "1     10,000,000.00            64,444.00\n",
      "2     10,000,000.00            64,444.00\n",
      "3     10,000,000.00            64,444.00\n",
      "...             ...                  ...\n",
      "57791          0.00            64,444.00\n",
      "52111          0.00            64,444.00\n",
      "31303          0.00            64,444.00\n",
      "16385          0.00            64,444.00\n",
      "50244          0.00            64,444.00\n",
      "\n",
      "[65437 rows x 2 columns]\n",
      "\n",
      "Summary of Missing Values:\n",
      "                 Column  Missing Values  Total Rows\n",
      "0  ConvertedCompYearly           42002       65437\n",
      "1            CompTotal           31697       65437\n",
      "\n",
      "Most Frequent Values (for each column):\n",
      " {'ConvertedCompYearly': np.float64(64444.0), 'CompTotal': np.float64(10000000.0)}\n",
      "\n",
      "Most Frequent Value Across the Columns: CompTotal             10,000,000.00\n",
      "ConvertedCompYearly       64,444.00\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82/1705533735.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[cols_to_check].replace(0, np.nan, inplace=True)\n",
      "/tmp/ipykernel_82/1705533735.py:19: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[cols] = df[cols].applymap(lambda x: min(x, 1e+7) if pd.notnull(x) else x)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Capping function\n",
    "import numpy as np\n",
    "\n",
    "# Function to handle missing values by imputing with the mode for categorical columns\n",
    "def cover_missing_values(cols):\n",
    "    # Calculate columns with missing values\n",
    "    columns_with_missing_values = df[cols].isnull().sum().sort_values(ascending=False)\n",
    "    df_missing = columns_with_missing_values[columns_with_missing_values > 0]\n",
    "\n",
    "    # Create summary for missing values\n",
    "    df_missing_summary = pd.DataFrame({\n",
    "        'Column': df_missing.index,\n",
    "        'Missing Values': df_missing.values,\n",
    "        'Total Rows': [df.shape[0]] * len(df_missing)\n",
    "    })\n",
    "\n",
    "    # Apply capping to columns if needed\n",
    "    df[cols] = df[cols].applymap(lambda x: min(x, 1e+7) if pd.notnull(x) else x)\n",
    "\n",
    "    # After capping, handle missing values by imputing with mode (for categorical columns)\n",
    "    for col in df_missing_summary['Column']:\n",
    "        mode_value = df[col].mode()[0]  # Get the mode of the column (most frequent value)\n",
    "        df[col] = df[col].fillna(mode_value)  # Impute missing values with mode\n",
    "    \n",
    "    # After imputing, show the capping and imputed values (drop NaN for inspection)\n",
    "    print(f\"After Capping and Imputation (Missing Values Filled with Mode):\\n{df[cols].dropna().sort_values(by=cols[0], ascending=False)}\")\n",
    "    \n",
    "    # Get most frequent values (modes) for each column\n",
    "    most_frequent_values = {col: df[col].mode()[0] for col in df_missing_summary['Column']}\n",
    "    \n",
    "    # For overall most frequent value in the dataset (e.g., `CompTotal` or `Employment`)\n",
    "    most_frequent_vc = df[cols].mode().iloc[0]  # The overall most frequent value across columns\n",
    "\n",
    "    return df_missing_summary, most_frequent_values, most_frequent_vc\n",
    "\n",
    "cols_to_check=['CompTotal','ConvertedCompYearly']\n",
    "\n",
    "# Replace 0 with NaN in the selected columns in-place\n",
    "df[cols_to_check].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Check for missing values after treating 0 as NaN\n",
    "columns_with_missing_values = df[cols_to_check].isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "# Display the number of missing values\n",
    "print(columns_with_missing_values)\n",
    "# Call the function to process columns\n",
    "df_missing_summary, most_frequent_values, most_frequent_vc = cover_missing_values(cols_to_check)\n",
    "\n",
    "# Output the results\n",
    "print(\"\\nSummary of Missing Values:\\n\", df_missing_summary)\n",
    "print(\"\\nMost Frequent Values (for each column):\\n\", most_frequent_values)\n",
    "print(\"\\nMost Frequent Value Across the Columns:\", most_frequent_vc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found two columns compensation-related in the dataset and the CompTotal max value is way too high its an outlier. I adjusted with the nearast max value i use the capping & imputing methods\n"
     ]
    }
   ],
   "source": [
    "print(\"Found two columns compensation-related in the dataset and the CompTotal max value is way too high its an outlier. I adjusted with the nearast max value i use the capping & imputing methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this lab, you focused on imputing missing values in the dataset.**\n",
    "\n",
    "- Use the <code>pandas.read_csv()</code> function to load a dataset from a CSV file into a DataFrame.\n",
    "\n",
    "- Download the dataset if it's not available online and specify the correct file path.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2024-11-05|1.3|Madhusudhan Moole|Updated lab|\n",
    "|2024-10-29|1.2|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-27|1.1|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-26|1.0|Raghul Ramesh|Created lab|\n",
    "--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "70ab641719bca2be0bdcb38f6a8b5de7851b6e9c28d41b9407096c62e74916a6"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
